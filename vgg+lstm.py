# -*- coding: utf-8 -*-
"""vgg+lstm.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zvlqNHQ-mjvyw2PFSQ76nYQAaJ1pEWD4
"""

import tensorflow as tf
from keras.applications.vgg16 import VGG16
from keras.models import Model
from keras.layers import Dense, Input
from keras.layers.pooling import GlobalAveragePooling2D
from keras.layers.recurrent import LSTM, GRU
from keras.layers.wrappers import TimeDistributed
from tensorflow.keras.optimizers import Nadam, Adam
from keras.models import Sequential,Model
from keras.layers.core import Dense, Dropout, Flatten
from keras.layers.convolutional import Convolution3D, MaxPooling3D, ZeroPadding3D
from tensorflow.keras.optimizers import SGD
from keras.layers import Add,Input,Conv3D,AveragePooling3D,MaxPooling2D,AveragePooling2D

frames, channels, rows, columns = 16,3,224,224

video = Input(shape=(frames,
                     rows,
                     columns,
                     channels))
#video = AveragePooling3D(pool_size=(1,2,2),strides=(1,2,2))(video)

cnn = Sequential()
cnn.add(Input(shape=(rows,columns,channels)))
cnn.add(AveragePooling2D(pool_size=(2,2),strides=(2,2)))
cnn.add(VGG16(weights='imagenet',include_top=False))
cnn.add(GlobalAveragePooling2D())
cnn.trainable = False

encoded_frames = TimeDistributed(cnn)(video)
encoded_sequence = LSTM(128)(encoded_frames)
hidden_layer = Dense(128, activation="relu")(encoded_sequence)
outputs = Dense(7, activation="softmax")(hidden_layer)

model = Model(video, outputs)
model.summary()

import sys
from google.colab import drive
drive.mount('/content/drive')

import pickle
import numpy as np
import pandas as pd
import os, glob
import gc

from pandas.io.common import file_path_to_url
train_data_dir = '/content/drive/MyDrive/FER2021fall/data/'
files = sorted(glob.glob(os.path.join(train_data_dir,'*.pkl')))
for file in files:
    print('Reading file {0}...........'.format(file))
    gc.collect()
    with open(file, 'rb') as rf:
        data = pickle.load(rf)
    for i in range(4):
        file_address = file[:-4] + '(' + str(i) + ').pkl'
        print(file_address) 
        data[i*500:(i+1)*500].to_pickle(file_address)

def train_batch_generator(train_data_dir = '/content/drive/MyDrive/FER2021fall/data/'):
    files = sorted(glob.glob(os.path.join(train_data_dir,'*.pkl')))
    label_file_path = os.path.join(train_data_dir,'labels.csv')
    f = pd.read_csv(label_file_path)
    print('going to operate on:',files)
    embeddings, labels = [], []
    label = list(f['label'])
    count = 0
    for file in files:
        print('Reading file {0}...........'.format(file))
        gc.collect()
        with open(file, 'rb') as rf:
            data = pickle.load(rf)
            val = list(data.values())
        for i in range(4):
            print('Reading part{0}...........'.format(i))
            new_val = np.asarray(val[i*500:(i+1)*500])
            print('count:',count)
            new_label = np.asarray(label[count*2000+i*500:count*2000+(i+1)*500])
            yield (new_val,new_label)
        count += 1

gc.collect()
hist = model.compile(optimizer="Nadam", loss="sparse_categorical_crossentropy", metrics=["acc"])
for x_train, y_train in train_batch_generator():
    gc.collect()
    model.fit(x_train, y_train, batch_size = 8, epochs = 15)

